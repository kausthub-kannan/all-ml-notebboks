{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nWYdaKml25EypE82MNVI0JebFBXof1O_","timestamp":1681637076644}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Coding Challenge\n","\n","Thank you for applying to this internship. To help us select and assess your ability to do applied computer vision, we are asking that you complete a short coding challenge. This coding challenge is not meant to take too long, do NOT spend more than 4-6 hours on them -- you can submit whatever you have.\n","\n","**How to submit**: Please make a copy of this colab notebook, add your code and results, and submit your colab notebook link along with your application. "],"metadata":{"id":"tmxLZl13cLnM"}},{"cell_type":"markdown","source":["**Generated by AI detector**: Train a model to detect if images are generated by AI\n","\n","* Find a dataset of natural images and images generated by AI (here is one such dataset on the [Hugging Face Hub](https://huggingface.co/datasets/competitions/aiornot) but you're welcome to use any dataset you've found.\n","* Create a training and test set.\n","* Build a neural network (using Tensorflow, PyTorch, or any framework you like)\n","* Train it to classify the image as being generated by an AI or not until a reasonable accuracy is reached\n","* Look at some of the images that were classified incorrectly. Please explain what you might do to improve your model's performance on these images in the future (you do not need to impelement these suggestions)\n","\n","**Submission instructions**: Please write your code below and include some examples of images that were classified"],"metadata":{"id":"01Y234jHcj9W"}},{"cell_type":"code","source":["!pip install datasets\n","# !pip install huggingface_hub\n","\n","# #Login to Hugging Face to access the Dataset\n","# import huggingface_hub\n","# huggingface_hub.notebook_login()\n","\n","from datasets import load_dataset\n","ds = load_dataset('competitions/aiornot')\n","ds = ds.with_format(\"tf\")\n","\n","test_data=ds[\"test\"]\n","train_data=ds[\"train\"]\n","\n","classes=[\"Non-AI Generated\", \"AI Generated\"]"],"metadata":{"id":"0vEX74l8b8a1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","\n","#Visualization\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n","from sklearn.utils import class_weight\n","\n","#Tensorflow\n","import tensorflow as tf\n","import tensorflow.keras.layers as lyrs\n","from tensorflow.keras.applications import ResNet50V2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import tensorflow_hub as hub\n","from tensorflow.keras.optimizers.legacy import Adam\n","\n","def supervised_metrics(y_true, y_pred):\n","    \"\"\"Meterics for a Supervised Learning model:\"\"\"\n","    print(\"Accuracy : {} %\".format(accuracy_score(y_true, y_pred)*100))\n","    print(\"F1 Score : {}\".format(f1_score(y_true, y_pred, average='weighted')))\n","    print(\"Recall : {}\".format(recall_score(y_true, y_pred, average='weighted')))\n","    print(\"Precision : {}\".format(precision_score(y_true, y_pred, average='weighted')))\n","    \n","def view_random_image(dataset,classes):\n","    random_image=random.randint(0,len(dataset))\n","    print(classes[dataset[random_image][\"label\"]])\n","    return dataset[random_image][\"image\"]\n","    \n","def pre_process_image(path, image_shape=224, channels=3, norm_factor=255.):\n","    '''Pre-Processing the Image before sending it to the model'''\n","    img = tf.io.read_file(path)\n","    img = tf.image.decode_image(img, channels=channels)\n","    img = tf.image.resize(img, size = (image_shape, image_shape))\n","    img = tf.expand_dims(img, axis=0)\n","    img = img/norm_factor\n","    return img\n","\n","def random_tester(root_path, classes, model, class_type=\"binary\"):\n","    '''Random Class Folder Selection'''\n","    path=root_path\n","    class_folder=random.choice(os.listdir(path))\n","    \n","    '''Random File Selection'''\n","    folder_path=path+'/'+class_folder+'/'\n","    rand=random.choice(os.listdir(folder_path))\n","    file_path=folder_path+'/'+rand\n","    random_image=mpimg.imread(file_path)\n","    \n","    '''Prediction'''\n","    predicted_value=model.predict(pre_process_image(file_path)) \n","    if(class_type==\"binary\"):\n","        predicted_label=classes[custom_rounder(predicted_value)]\n","    else:\n","        index=tf.math.round(predicted_value).numpy()\n","        index=np.argmax(index)\n","        predicted_label=classes[index]\n","        \n","    '''Visualize'''\n","    plt.imshow(random_image)\n","    plt.title(\"Prediction:\" + predicted_label +\"\\n\" +\"True class: \"+ class_folder)\n","    plt.show()\n","    \n","def loss_curve_plot(df):\n","    \"\"\" Dataframe (df) is history of the fit of the NN model\n","    The df consists of train and validation fit data\n","    \"\"\"\n","    history = df.history\n","    val_accuracy = history[\"val_accuracy\"]\n","    val_loss = history[\"val_loss\"]\n","    train_accuracy = history[\"accuracy\"]\n","    train_loss = history[\"loss\"]\n","    \n","    \"\"\"Accuracy Plot\"\"\"\n","    plt.plot(train_accuracy, label=\"Train Accuracy\")\n","    plt.plot(val_accuracy, label=\"Validation Accuracy\")\n","    plt.title(\"Accuracy Curves\")\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.legend()\n","    plt.show()\n","    \n","    \"\"\"Loss Plot\"\"\"\n","    plt.plot(train_loss, label=\"Train loss\")\n","    plt.plot(val_loss, label=\"Validation loss\")\n","    plt.title(\"Loss Curves\")\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend()\n","    plt.show()\n","    \n","def confusion_matrix_plot(y_true, y_pred, figsize=(30,30)):\n","    \"\"\"\"Confusion Matrix for true values and predicted values\"\"\"\n","    cm = metrics.confusion_matrix(y_true, y_pred)\n","    cm = cm.astype('float') / cm.sum(axis=1)\n","    plt.figure(figsize = figsize)\n","    sns.heatmap(cm, annot=True, cmap=\"crest\")"],"metadata":{"id":"D37gUOT3ckFf","executionInfo":{"status":"ok","timestamp":1681642979967,"user_tz":-330,"elapsed":2003,"user":{"displayName":"Kausthub Kannan","userId":"16531519236785994511"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE=224\n","view_random_image(train_data, classes)"],"metadata":{"id":"m93geqzQbymT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    validation_split=0.2,\n","    rescale=1./255\n",")\n","\n","train_datagen = datagen.flow(\n","    train_data,\n","    batch_size=32,\n","    subset='training'\n",")\n","\n","test_datagen = datagen.flow(\n","    test_data,\n","    batch_size=32,\n",")"],"metadata":{"id":"VWaBvJJeeaJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data[0:3000][\"image\"]"],"metadata":{"id":"KkR8BDq-tDL-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0XKdb28_nzXv"},"execution_count":null,"outputs":[]}]}